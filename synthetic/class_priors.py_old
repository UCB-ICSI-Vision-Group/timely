from IPython.parallel import Client
from string import atof
import scipy.stats as st
import matplotlib.pyplot as plt
from sklearn.cross_validation import KFold

from common_imports import *
from common_mpi import *


from synthetic.sliding_windows import WindowParams
from synthetic.priorsJT import PriorsJT

class ClassPriors:
  """
  Encapsulation of the part of the belief state that keeps track of the object class priors.
  Methods to initialize the model, update with an observed posterior, and
  condition on observed values.
  """

  accepted_modes = ['random','oracle','fixed_order','no_smooth','backoff', 'junction_tree']

  def __init__(self, dataset, mode='random'):
    self.dataset = dataset
    data = self.dataset.get_cls_counts()

    assert(mode in ClassPriors.accepted_modes)
    self.mode = mode

    if mode=='random':
      self.model = RandomModel(data)
    elif mode=='oracle':
      self.model = RandomModel(data)
    elif mode in ['fixed_order','no_smooth','backoff']:
      self.model = NGramModel(data,self.mode)
    elif mode=='junction_tree':
      self.model = PriorsJT(self.dataset)
    else:
      raise RuntimeError("Unknown mode")
    self.priors = self.model.get_probabilities()
    self.observed_inds = []
    self.observed_vals = []

  def __repr__(self):
    return "ClassPriors: \n%s\n%s"%(self.priors,zip(self.observed_inds,self.observed_vals))

  def update_with_posterior(self, cls_ind, posterior):
    """
    Update the priors given the observed posterior of one class.
    """
    # TODO: for now, just set to hard 0/1
    self.observed_inds.append(cls_ind)
    self.observed_vals.append(posterior)
    self.priors = self.model.get_probabilities(self.observed_inds,self.observed_vals)
    
  def update_with_gist(self, gist_priors):
    """
    Update the priors given the GIST-conditioned class probabilities.
    """
    # TODO: not quite clear what to do
    new_priors = []
    for i in range(len(self.priors)):
      new_priors.append(self.priors[i]*gist_priors[i])
    self.priors = new_priors
  
  def evaluate_marginal_prob_error(self):
    # TODO: investigate modes other than the default 'no_smooth' here
    data = self.dataset.get_cls_counts()
    num_folds = 4
    loo = KFold(data.shape[0], num_folds)
    errors = []
    for train,val in loo:
      model = NGramModel(data[train,:])
      val_data = data[val,:]
      val_model = NGramModel(val_data)
      num_unknown = 0
      for row in val_data:
        cls_inds = np.flatnonzero(row)
        pred_prob = model.marg_prob(cls_inds)
        actual_prob = val_model.marg_prob(cls_inds)
        error = abs(pred_prob-actual_prob)
        errors.append(error)
        if pred_prob == 0:
          num_unknown += 1
      print("Num unknown: %d/%d"%(num_unknown,val_model.shape()[0]))
    filename = config.class_priors_plot%'marginal_prob_error'
    title = "Error of predicted vs. true marginal probability for 4-fold validation on the trainval set"
    self.plot_dist(errors,filename,title=title)

  def evaluate_method(self,lam1, lam2, parallel=False):
    data = self.dataset.get_cls_counts()
    num_folds = 4
    loo = KFold(data.shape[0], num_folds)
    
    modes={}
    #modes['no_smooth'] = [(data,train,val,'no_smooth') for train, val in loo]
    modes['backoff'] = [(data,train,val,'backoff',lam1,lam2) for train, val in loo]
    #modes['random'] = [(data,train,val,'random') for train, val in loo]
    for mode,params in modes.items():
      t = time.time()
      if parallel:
        rc = Client()
        lview = rc.load_balanced_view()
        lview.block = True
        results = lview.map(predict_rows_split, params)
      else:
        results = map(predict_rows_split,params)

      all_losses = [x[0] for x in results]
      all_taken = [x[1] for x in results]

      # turn from a list of list of lists to a list of lists :-)
      all_losses = reduce(lambda x,y: x+y, all_losses)
      all_taken = reduce(lambda x,y: x+y, all_taken)

      all_losses = np.vstack(all_losses)
      all_taken = np.vstack(all_taken)
      print("time elapsed: %.3f"%(time.time()-t))

#      print(all_taken[:5,:])

      # plot
      means = np.mean(all_losses,0)
      x = np.arange(data.shape[1])
      auc = np.trapz(means,x)
      if comm_rank == 0:
        plt.errorbar(x, y=means, yerr=np.std(all_losses,0), label="%s: %.3f"%(mode,auc))
    if comm_rank == 0:
      plt.legend()
      plt.title('Perfect Class Prediction Loss, 4-Fold Cross-Validation')
      plt.xlabel('# actions taken',size='large')
      plt.ylabel('loss (fraction of ground truth correctly covered)',size='large')
      plt.savefig(os.path.join(config.res_dir,'cross_val_lam1_lam2/')+'fig_'+str(lam1)+'_'+str(lam2)+'.png')
    return auc

def predict_rows_split(params):
  """
  Params should be a tuple of
    - data: ndarray of image-object counts
    - train: indicator ndarray for training rows
    - val: indicator ndarray for val rows
    - mode: which mode to use in predict_row()
  """
  print 'predict with params', params[4], params[5]
  from synthetic.class_priors import NGramModel
  data = params[0]
  train = params[1]
  val = params[2]
  mode = params[3]
  model = NGramModel(data[train,:], mode=mode)
  lam1 = params[4]
  lam2 = params[5]
  results = [model.predict_row(row, lam1, lam2) for row in data[val,:]]
  losses = [x[0] for x in results]
  taken = [x[1] for x in results]
  return (losses,taken)

class RandomModel:
  def __init__(self,data):
    self.num_classes = data.shape[1]

  def get_probabilities(self, cond_inds=None, cond_vals=None): 
    return np.random.rand(self.num_classes)

class NGramModel:
  # TODO: does not use random mode in the cond_prob and marg_prob methods

  accepted_modes = ['random','fixed_order','no_smooth','smooth','backoff']

  def __init__(self,data,mode='random'):
    self.data = data
    self.cache = {}
    assert(mode in NGramModel.accepted_modes)
    self.mode = mode
    self.cls_inds = range(self.data.shape[1])
    print("NGramModel initialized with %s mode"%self.mode)

  def shape(self): return self.data.shape

  def get_probabilities(self, cond_inds=None, cond_vals=None):
    """Return list of the values of each cls_ind."""
    if self.mode=='fixed_order':
      return [self.cond_prob(cls_ind) for cls_ind in self.cls_inds]
    else:
      return [self.cond_prob(cls_ind, cond_inds, cond_vals) for cls_ind in self.cls_inds]

  def predict_row(self, row, lam1, lam2):
    """
    Predict the value of the row element-by-element.
    After each prediction:
      - the value of the loss function is recorded;
      - the ground truth for that element is revealed.
    Return list of the loss function values (always 20, because every element
    is investigated.
    """
    num_actions = self.shape()[1]
    actions = list(range(num_actions))
    taken = []
    observed_inds = []
    observed_vals = []
    losses = []
    while len(taken)<num_actions:
      # pick best action
      if self.mode=='no_smooth' or self.mode=='smooth' or self.mode=='backoff':
        values = [self.cond_prob(cls_ind, observed_inds, observed_vals, lam1=lam1, lam2=lam2) for cls_ind in actions] 
        values_vec = -np.ones(num_actions)
        values_vec[actions] = values
        action = np.argmax(values_vec)
      elif self.mode=='random':
        action = actions[np.random.randint(0,len(actions))]
      taken.append(action)
      actions.remove(action)
      # get loss, which is the ratio of ground truth that we haven't found to
      # total ground truth
      loss = 1.*(np.count_nonzero(row) - np.sum(observed_vals))/np.count_nonzero(row)
      losses.append(loss)
      # get ground truth
      observed_inds.append(action)
      val = 1 if row[action]>0 else 0
      observed_vals.append(val)
    return (losses,taken)

  def marg_prob(self, cls_inds, vals=None):
    """
    Returns the marginal probability of a given list of cls_inds being assigned
    the given vals.
    """
    if not isinstance(cls_inds, types.ListType):
      cls_inds = [cls_inds]

    # If vals aren't given, set all to 1
    if vals == None:
      vals = [1. for cls_ind in cls_inds]
    else:
      if not isinstance(vals, types.ListType):
        vals = [vals]

    # check if we've already computed value for this
    hash_string = ' '.join(["%d:%d"%(int(x),int(y)) for x,y in zip(cls_inds,vals)])
    if hash_string in self.cache:
      return self.cache[hash_string]

    num_total = self.data.shape[0]
    rep_vals = np.tile(vals,(num_total,1))
    inds = np.all(self.data[:,cls_inds]==rep_vals,1)[:]
    filtered = self.data[inds,:]
    num_filtered = filtered.shape[0]

    ans = 1.*num_filtered/num_total
    #print("The marginal probability of %s is %s"%(cls_inds,ans))
    self.cache[hash_string] = ans
    return ans

  def cond_prob(self, cls_inds, cond_cls_inds=None, vals=None, lam1=0.05, lam2=0.):
    """
    Returns the conditional probability of a given list of cls_inds, given
    cond_cls_inds. If these are None, then reverts to reporting the marginal.
    Arguments must be lists, not ndarrays!
    Accepted modes:
      - 'no_smooth': the standard, allows 0 probabilities if no data is present
      - 'backoff': P(C|A) is approximated by P(C,A)/P(A) + \lambda*P(C)
      - 'smooth': NOT IMPLEMENTED
    """
    if not isinstance(cls_inds, types.ListType):
      cls_inds = [cls_inds]

    # if no conditionals given, return marginal
    if cond_cls_inds == None:
      return self.marg_prob(cls_inds)

    if not isinstance(cond_cls_inds, types.ListType):
      cond_cls_inds = [cond_cls_inds]

    # If vals aren't given, set all to 1
    if vals == None:
      vals = [1. for cls_ind in cond_cls_inds]
    else:
      if not isinstance(vals, types.ListType):
        vals = [vals]

    # check if cls_inds are in cond_cls_inds and return their vals if so
    # TODO: generalize to the list case
    assert(len(cls_inds)==1)
    if cls_inds[0] in cond_cls_inds:
      ind = cond_cls_inds.index(cls_inds[0])
      return vals[ind]

    # check if we've cached this conditional
    sorted_inds = np.argsort(cond_cls_inds)
    sorted_cond_cls_inds = np.take(cond_cls_inds, sorted_inds)
    sorted_vals = np.take(vals, sorted_inds)
    hash_string = ' '.join([str(x) for x in sorted(cls_inds)])
    hash_string += '|' + ' '.join(["%d:%d"%(int(x),int(y)) for x,y in zip(cond_cls_inds,vals)])
    if hash_string in self.cache:
      return self.cache[hash_string]

    cls_ind_vals = [1. for cls_ind in cls_inds]
    joint_vals = cls_ind_vals+vals
    joint_prob = self.marg_prob(cls_inds+cond_cls_inds, joint_vals)
    prior_prob = self.marg_prob(cond_cls_inds, vals)
    if prior_prob == 0:
      ans = 0.
    else:
      ans = joint_prob/prior_prob

    # TODO: cross-validate this parameter
    if self.mode=='backoff' and len(cond_cls_inds) > 0 :      
      ans = (1-lam1-lam2)*ans + lam2*self.marg_prob(cls_inds)
      # k pairwise cond
      sum_cond = 0.
      for other_ind in range(len(cond_cls_inds)):
        joint = self.marg_prob([cls_inds[0], cond_cls_inds[other_ind]], [1, vals[other_ind]])
        prior = self.marg_prob(cond_cls_inds[other_ind], vals[other_ind]) 
        if prior == 0:
          sum_cond += 0.
        else:
          sum_cond += joint/prior
      ans += lam1*sum_cond*(1./len(cond_cls_inds))
    self.cache[hash_string] = ans
    return ans

  @classmethod
  def test_self(cls):
    data = np.array([
      [1,0,0,0], #A
      [0,1,0,0], #B
      [1,1,0,0], #AB
      [1,1,1,0], #ABC
      [0,0,0,1]  #D
      ])

    model = NGramModel(data,'no_smooth')

    # some marginals
    assert(model.marg_prob(0) == 0.6)
    assert(model.marg_prob([0]) == 0.6)
    assert(model.marg_prob([1]) == 0.6)
    assert(model.marg_prob([0,1]) == 0.4)
    assert(model.marg_prob([2]) == 0.2)
    assert(model.marg_prob([3]) == 0.2)

    # now some conditional probabilities
    assert(ut.fequal(model.cond_prob([1],[0]), 0.666666666))
    # B | A=1
    assert(ut.fequal(model.cond_prob(1,0), 0.666666666))
    # B | A=0
    assert(ut.fequal(model.cond_prob(1,0,0), 0.5))
    # C | A=1,B=1
    assert(ut.fequal(model.cond_prob([2],[0,1]), 0.5))
    # C | A=1,B=0
    assert(ut.fequal(model.cond_prob([2],[0,1], [1,0]), 0))

    # now a never-before seen marginal
    assert(model.marg_prob([3]) == 0.2)
    assert(model.marg_prob([0,3]) == 0)

def find_best_lam1_lam2(filename):
  infile = open(filename,'r').readlines()
  minimum = 100000.
  bestvals = 0
  for line in infile:
    entries = line.split()
    score = atof(entries[2])
    if score < minimum:
      minimum = score
      bestvals = entries
  print bestvals

if __name__ == '__main__':
  NGramModel.test_self()

  from synthetic.dataset import Dataset
  dataset = Dataset('full_pascal_trainval')
  cp = ClassPriors(dataset, 'no_smooth')
  
  find_best_lam1_lam2(os.path.join(config.res_dir,'cross_val_lam1_lam2/')+'auc.txt')

  #cp.evaluate_marginal_prob_error()
  lams = []
  for lam1 in np.arange(0,1,0.05):
    for lam2 in np.arange(0,1-lam1,0.05):
      lams.append((lam1,lam2))
  cp.evaluate_method(0.05, 0)
#  auc_file = open(os.path.join(config.res_dir,'cross_val_lam1_lam2/')+'auc.txt','a')
#  for lamdex in range(comm_rank, len(lams), comm_size):
#    lam = lams[lamdex]
#    auc = cp.evaluate_method(lam[0], lam[1])
#    auc_file.write(str(lam[0])+' '+str(lam[1])+ ' '+str(auc)+'\n')



