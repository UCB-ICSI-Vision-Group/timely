\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{graphicx}
\usepackage{amsmath,amssymb} % define this before the line numbering.
\usepackage{color}
\usepackage{subfig}
\usepackage{natbib}
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\def\subsectionautorefname{section}
\definecolor{light-gray}{gray}{0.5}
\newcommand{\aside}[1]{\textcolor{light-gray}{\emph{#1}}}
\newcommand{\todo}[1]{\textcolor{red}{\emph{#1}}}
\newcommand{\cut}[1]{\textcolor{light-gray}{#1}}
\newcommand{\comment}[1]{}

\newcommand{\myparagraph}[1]{\vspace{-0.1cm}{\bf #1}}

\title{Timely Object Recognition}

\author{
Sergey Karayev \And
Tobias Baumgartner \And
Mario Fritz \And
Trevor Darrell
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}
\maketitle

\begin{abstract}
In a large visual multi-class detection framework, the problem of timeliness of results is crucial.
We are motivated by situations where running all detectors would take an unacceptably long time, and the best answer must be given by some deadline.
Our method for multi-class detection aims to give the best possible performance at any single point after a start time; it is terminated at a deadline time.
Toward this goal, we formulate a dynamic, \emph{closed-loop} policy guided by inference of the contents of the image in order to decide which detector to deploy next.
In contrast to previous work, our method significantly diverts from the predominant greedy strategies and therefore learns to employ actions without any immediate reward for the goal of detection.
We evaluate our method with respect to performance in the novel Average Precision (AP) vs. Time evaluation on the widely used PASCAL VOC object detection dataset.
With our method, if execution is stopped when only half the detectors have been run, our method obtains $66\%$ better AP than a random ordering, and $14\%$ better performance than an intelligent baseline.
Overall, our method obtains at least $11\%$ better performance on the AP vs. Time evaluation. At time of publication we will make our code available, which is easily extendible to new detectors, classifiers, tasks and reward functions due to the modular nature of our formulation.
\end{abstract}

\input{introduction.tex} % includes Evaluation section
\input{related.tex}
\input{technical.tex}
\input{evaluation.tex}

\section{Conclusion}
We presented a method for learning ``closed-loop'' policies for multi-class object recognition, given existing object detectors and classifiers and a metric to optimize.
The method learns the optimal policy using reinforcement learning, by observing execution traces in training.
If detection on an image is cut off after only half the detectors have been run, our method does $66\%$ better than random, and $14\%$ better than an intelligent baseline. In particular, our method learns to take action with no intermediate reward in order to improve the overall performance of the system.

As always with reinforcement learning problems, the defining the reward function requires some manual work.
Here, we derive it for the novel detection AP vs. Time evaluation that we suggest is most useful for evaluating efficiency in recognition.
Although computation devoted to scheduling actions is much less significant than the computation due to running the actions, an interesting future research direction is to explicitly consider this decision-making cost.

At time of publication, we will release the code of our modular framework, that allows for easy incorporation of other classifiers and detectors on different tasks and rewards.

% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments go at the end of the paper. Do not include 
% acknowledgments in the anonymized submission, only in the 
% final paper. 

\renewcommand\bibsection{\subsubsection*{\refname}}
\bibliographystyle{unsrt}
\small{
  \bibliography{../sergeyk_Timely}
}

\end{document}
