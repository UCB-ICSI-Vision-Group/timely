\section{Recognition Problems and Related Work}

We deal with a dataset of images $\mathcal{D}$, where each image $\mathcal{I}$ contains at least one, and often multiple, objects.
Each object is labeled with exactly one category label $k \in \{1, \dots, K\}$.

The multi-class, multi-label \textbf{classification} problem asks whether $\mathcal{I}$ contains at least one object of class $k$.
We write the ground truth for an image as $\mathbf{C}=\{C_1,\dots,C_K\}$, where $C_k \in \mathbb{B} = \{0,1\}$ is set to $1$ if an object of class $k$ is present.

The \textbf{detection} problem is to output a list of bounding boxes (sub-images defined by four coordinates), each with a real-valued confidence that it encloses a single instance of an object of class $k$, for each $k$.
The answer for a single class is given by an algorithm $\emph{detect}(\mathcal{I},k)$, which outputs a list of sub-image bounding boxes $B$ and their associated confidences.

The answer is evaluated by plotting precision vs. recall across dataset $\mathcal{D}$ (by progressively lowering the confidence threshold for a positive detection).
The area under the curve yields the Average Precision (AP) metric, which has become the standard evaluation for recognition performance on challenging datasets in vision \cite{pascal-voc-2010}.
A common measure of a correct detection is the PASCAL overlap: two bounding boxes are considered to match if they have the same label and the ratio of their intersection to their union is at least $\frac{1}{2}$.

To highlight the hierarchical structure of these problems, we note that (1) the confidences for each sub-image $b \in B$ may be given by $\emph{classify}(b,k)$; (2) correct answer to the detection problem also answers the classification problem.

\subsection{Related Work}
The literature on object detection is vast.
Here we briefly summarize detection work that sufficiently contextualizes our contribution in the areas of object classification and detection in context, saliency, multi-class prediction, steering of computation (such as in cascades, any time algorithm) and active classification.

\paragraph{Contect}
Context of course has a long history in vision.
One source of context is the scene or non-detector cues; for the PASCAL VOC, these are quantitatively considered in~\cite{Divvala2009}. 
Another source is inter-object context, used for detection in a random field setting in~\cite{Torralba2004}. These  statistics interlink individual object detection tasks as well as image classification. Exploiting this information has shown to improve classification as well as detection tasks (e.g. \cite{Torralba, visual phrases}).
A critical summary of the main approaches to using context for object detection is given in \cite{Galleguillos2010}.

\paragraph{Multi-Class Detection}
Inherently multi-class detection has its own line of work, focusing largely on making detection time sublinear in the number of classes through sharing features~\cite{Torralba2007,Fan2005,Razavi2011}.
A recent post-processing extension to detection systems uses structured prediction to incorporate multi-class context as a principled replacement for the common post-processing step of non-maximum suppression~\cite{Desai2009}. Most critically, theses methods don't use intermediate results in order to maximize the joint detection performance.

\paragraph{Attention and Steering of Computation}
An early success in efficient object detection used simple Haar features to build up a \emph{cascade} of classifiers, which then considered image regions in a sliding window regime~\cite{Viola2001}.
Although the simple features and classifiers of this method have been surpassed by more complex detectors, the idea of cascading classifier evaluations is still often used.

The best recent performance has come from detectors that use gradient-based features to represent objects as either a collection of local patches or as object-sized windows \cite{Dalal2005,Lowe2004}.
Usually, SVM classifiers are used to learn separating hyperplanes in such feature spaces between objects of a given class and all other possible contents of an image window. One of the state of the art classifiers available to us today builds upon a linear classifier on gradient representation which is sped up with a cascaded evaluation scheme \cite{DPM-cascade}[

Window proposal is often done exhaustively over the image space, in a ``sliding window'' fashion.
Using ``jump windows'' (window hypotheses voted on by local features) as region proposals is another common idea~\cite{Chum2007b,Vedaldi2009,Vijayanarasimhan2011}.
For local feature-based approaches, a bounded search over the space of all possible windows works reasonably well~\cite{Lampert2008b}---however, the method has not been able to obtain state-of-the-art performance.

Although none of the best-performing systems treat window proposal and evaluation as a closed-loop system, with feedback from evaluation to proposal, some work has been done in the area, mostly inspired by ideas from biological vision and attention research~\cite{Butko2009,Vogel2008,Paletta2005}.

\paragraph{Anytime Algorithms}
Although an important concept, anytime performance in vision systems is a surprisingly little-explored idea \cite{Shlomo Zilberstein}.
A recent application to the problem of visual detection picks features with maximum value of information in a Hough-voting framework, and explicitly evaluates performance vs. time \cite{Vijayanarasimhan2010}. 
Also recent work on greedy methods and submodular formulations propose strategies for classifier/sensor evaluations in order to maximize information gain. Due to the aforementioned interlink between image classification and detection problems, anytime algorithms and greedy strategies seem counter intuitive and we therefore seek a "detection on a budget" formulation. In this fashion we can explore policies that don't yield any immediate reward.

\paragraph{Active Classification}
While most of the referenced work followed a rigid classification strategy at test time, there has been work on active classification \cite{Active Classification based on Value of Classifier}
 and active sensing  \cite{active sensing} which considers intermediate results in order to schedule the execution of further classification step. We provide a treatment of this topic for object detection that can be simply learned from traces of the system and can therefore also be easily be adapted to different loss functions.


